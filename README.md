# pytorch-notes

### 🔰 Stage 1: Beginner — Getting Started with PyTorch

**✅ Prerequisites**

- Python (functions, OOP, NumPy)
- Basic Linear Algebra & Calculus
- Basic Machine Learning


**🎯 Goals**

- Understand tensors
- Learn the PyTorch workflow
- Implement simple neural networks


**📚 Topics to Learn**

- Installing PyTorch (CPU/GPU)
- Tensors: creation, indexing, reshaping, operations
- Autograd and computation graph
- Basic neural networks (feedforward)
- Loss functions and optimizers
- Training loop from scratch


**🛠️ Projects**

- Linear regression with PyTorch tensors
- Classify MNIST digits using a simple MLP

---

### 🧠 Stage 2: Intermediate — Deep Learning with PyTorch

**🎯 Goals**

- Use torch.nn and torch.optim
- Master data loading and transformations
- Train CNNs and RNNs
- Learn transfer learning


**📚 Topics to Learn**

- torch.nn.Module and model subclassing
- torch.optim optimizers (SGD, Adam, etc.)
- Dataset & DataLoader APIs
- Transforms (torchvision.transforms)
- Convolutional Neural Networks (CNNs)
- Recurrent Neural Networks (RNNs, LSTMs)
- Transfer learning and fine-tuning
- Saving/loading models (state_dict)


**🛠️ Projects**

- CIFAR-10 image classifier with CNNs
- Text sentiment classification using LSTMs
- Fine-tune a pretrained ResNet on a custom dataset

---

### 🔬 Stage 3: Advanced — Customization and Optimization

**🎯 Goals**

- Customize models, losses, training loops
- Optimize performance
- Integrate PyTorch with research workflows


**📚 Topics to Learn**

- Custom loss functions
- Custom layers and modules
- Mixed-precision training (torch.cuda.amp)
- Learning rate schedulers
- Gradients clipping and accumulation
- Handling imbalanced datasets
- TensorBoard and logging
- Model export (TorchScript, ONNX)


**🛠️ Projects**

- GANs (Generative Adversarial Networks)
- Image segmentation with U-Net
- Multi-label classification task

---

### 🧪 Stage 4: Research-Level Mastery

**🎯 Goals**

- Work with large-scale datasets and models
- Implement research papers from scratch
- Contribute to the PyTorch ecosystem


**📚 Topics to Learn**

- Distributed training (DDP)
- PyTorch Lightning or torch.compile
- Writing clean, modular codebases
- Reproducibility and experiment tracking
- Custom backprop and autograd functions
- Working with HuggingFace Transformers


**🛠️ Projects**

- Reproduce a paper from arXiv (e.g., ViT, BERT, DDPM)
- Build a scalable training pipeline with Lightning
- Train a transformer model from scratch

---

**📦 Tools to Learn Alongside**

- torchvision, torchaudio, torchtext
- matplotlib, seaborn for visualization
- TensorBoard or Weights & Biases
- Hydra or MLflow for experiment management
- Docker for environment consistency

---

**📖 Suggested Resources**

1. Tutorials

- PyTorch Official Tutorials
- Deep Learning with PyTorch (book)


2. Courses

- FastAI – Practical deep learning with PyTorch
- Deep Learning Specialization (Coursera) + PyTorch adaptation
- CS231n, CS224n — for theory (code in PyTorch optionally)
